{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = Libraries to read in\n",
    "import os, sys\n",
    "\n",
    "# === key keras parts to create model ===\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
    "from keras.preprocessing.text import Tokenizer # use this instead of nltk\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# put in matrix format and plot networks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snake\n",
      "angwi) pl. (angu ango misery <eos>\n",
      "<sos> angwi) pl. (angu ango misery\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "\n",
    "quenya_dict_source = 'Quenya_dict.csv'\n",
    "\n",
    "os.getcwd()\n",
    "os.path.exists('/Users/MStamp/Documents/AIA Workshop/NLP Local Programme Workshop/Code Structure/Attempts of Translation/Quenya/Quenya_dict.csv')\n",
    "os.chdir('/Users/MStamp/Documents/AIA Workshop/NLP Local Programme Setup/Code Structure/Attempts of Translation/Quenya')\n",
    "\n",
    "quenya_dict = pd.read_csv(quenya_dict_source, dtype = 'str')\n",
    "\n",
    "\n",
    "# apply input and output sentences\n",
    "inputs = list(quenya_dict['english'])\n",
    "outputs = [str(word) + ' <eos>' for word in quenya_dict['quenya']]\n",
    "output_sent_inputs = ['<sos> ' + str(word) for word in quenya_dict['quenya']]\n",
    "\n",
    "ex_val = 146\n",
    "print(inputs[ex_val] + '\\n' + outputs[ex_val] + '\\n' + output_sent_inputs[ex_val])\n",
    "\n",
    "Max_num_words = 400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5531"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== Tokenization & Padding \n",
    "\n",
    "Total_inputs = len(inputs)\n",
    "Total_inputs = Max_num_words # make smaller\n",
    "\n",
    "input_tokenizer = Tokenizer(num_words = Total_inputs)\n",
    "\n",
    "# have to change code type\n",
    "inputs = [str(word) for word in inputs]\n",
    "\n",
    "input_tokenizer.fit_on_texts(inputs) # apply with inputs in English - issue as float object has no attribute\n",
    "\n",
    "input_int_seq = input_tokenizer.texts_to_sequences(inputs)\n",
    "input_int_seq[ex_val]\n",
    "\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "# - word2idx_inputs[ex_val]\n",
    "\n",
    "word2idx_inputs[inputs[ex_val].lower().split(' ')[0]]\n",
    "len(word2idx_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == apply same to output\n",
    "\n",
    "Total_outputs = len(outputs)\n",
    "Total_outputs = Max_num_words # also smaller\n",
    "\n",
    "output_tokenizer = Tokenizer(num_words=Total_outputs, filters='') #\n",
    "output_tokenizer.fit_on_texts(outputs + output_sent_inputs)\n",
    "# should be here as combi\n",
    "\n",
    "\n",
    "output_int_seq = output_tokenizer.texts_to_sequences(outputs)\n",
    "output_input_int_seq = output_tokenizer.texts_to_sequences(output_sent_inputs)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 17,  0, ...,  0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Padding need to get max lens in order to correctly pad sequences\n",
    "max_input_len = max(len(sen) for sen in input_int_seq)\n",
    "max_output_len = max(len(sen) for sen in output_int_seq) # not output - input - would expect to be longer as have <eos> at end\n",
    "# smaller in this case - as just word for word changes\n",
    "\n",
    "\n",
    "encoder_input_seq = pad_sequences(input_int_seq, maxlen = max_input_len)\n",
    "encoder_input_seq.shape\n",
    "encoder_input_seq[ex_val]\n",
    "# as only two words - see three output\n",
    "decoder_input_seq = pad_sequences(output_input_int_seq, maxlen = max_output_len, padding = 'post')\n",
    "decoder_input_seq[ex_val] # only two seen in any output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === much larger output values - can see longer sentence structure\n",
    "\n",
    "# from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "\n",
    "glove_source = '/Users/MStamp/Documents/AIA Workshop/NLP Local Programme Setup/Code Structure/Pre Made Translation Corpus/glove.42B.300d.txt'\n",
    "\n",
    "# open\n",
    "glove_file =  open(glove_source, encoding=\"utf8\")\n",
    "\n",
    "# get dim output\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "glove_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 400 is out of bounds for axis 0 with size 400",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a1e47360444e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings_dictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[0;31m# with reduction of total - this will be impeded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mexample_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'fridge'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 400 is out of bounds for axis 0 with size 400"
     ]
    }
   ],
   "source": [
    "# ==== Create Embedding Layer ====\n",
    "\n",
    "num_words = min(Total_inputs, len(word2idx_inputs) + 1)\n",
    "\n",
    "emb_size = 300\n",
    "\n",
    "embedding_matrix = zeros((num_words, emb_size))\n",
    "\n",
    "\n",
    "for word,index in word2idx_inputs.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[index] = embedding_vector # with reduction of total - this will be impeded\n",
    "\n",
    "example_text = 'fridge'\n",
    "\n",
    "print(embeddings_dictionary[example_text])\n",
    "\n",
    "embedding_layer = Embedding(num_words, emb_size , weights=[embedding_matrix], input_length=max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.2880e-01 -6.7593e-03 -2.4340e-01  4.9482e-02  5.3523e-01 -4.3863e-02\n",
      " -1.7705e+00 -3.4968e-02  3.1769e-01 -5.8027e-01  8.8206e-02 -3.6729e-01\n",
      " -5.2296e-02  6.7268e-01 -2.0580e-01 -2.3138e-01 -2.4324e-01 -4.3787e-02\n",
      " -1.6773e-01  9.5614e-02  6.2529e-02 -4.7919e-01 -1.9585e-01  2.8838e-01\n",
      " -4.2570e-01 -2.1769e-01  3.2729e-01  5.4468e-01  9.3767e-01 -4.7373e-01\n",
      " -2.0551e-01 -8.0361e-02 -4.8719e-01  5.2029e-02  5.6219e-01  2.5820e-01\n",
      " -1.5082e-01  4.0425e-01 -6.1659e-01 -2.7654e-01 -3.8402e-01 -3.1740e-01\n",
      " -2.2097e-01 -4.1795e-01 -1.4965e-01 -4.4497e-02  4.9798e-01 -3.7579e-02\n",
      "  7.2490e-02 -6.9846e-01 -6.3166e-01  2.8624e-01  6.7615e-02 -5.2663e-02\n",
      "  2.1006e-01  1.8085e-01  3.5130e-01 -1.3700e-01 -2.7910e-01 -2.1344e-01\n",
      "  2.4892e-01  5.4115e-02 -1.2008e-02  1.4010e-01  3.4760e-02 -6.4579e-01\n",
      "  3.2657e-01  1.9191e-01  3.1804e-01  2.8933e-01 -1.7503e-01 -2.1462e-01\n",
      " -2.0943e-01 -3.5404e-01  1.5801e-01  3.3117e-01  1.1115e-01 -3.7901e-01\n",
      "  5.8188e-01  1.6978e-01  1.6933e-01  9.9021e-01 -1.0299e-01  8.1427e-01\n",
      " -6.7585e-01 -3.4496e-02 -5.3243e-01  7.2931e-01 -3.2816e-01 -1.7433e-01\n",
      "  5.4918e-02 -7.6225e-01 -2.4561e-01  2.7541e-01  2.8828e-01 -1.2436e+00\n",
      " -3.2742e-01 -3.0831e-01 -4.4678e-01 -2.3036e-01 -3.2133e-01 -5.8245e-01\n",
      "  6.5605e-01  8.1942e-01 -8.1570e-01  4.8160e-01 -1.3835e-01  8.5136e-02\n",
      "  2.5913e-01  3.7154e-01  3.6087e-01 -4.4916e-01  1.5871e-01 -2.0325e-01\n",
      "  1.6526e-01  1.9026e-01  4.5484e-02  2.2985e-01  6.7343e-01 -1.7228e-02\n",
      "  3.3045e-01 -9.8850e-02  1.8250e-01  3.9587e-01  5.0317e-01  7.5545e-01\n",
      " -4.3906e-01 -6.3560e-01  1.5454e-01  5.0194e-02 -2.9877e-01 -2.6753e-01\n",
      "  3.1353e-01 -1.4370e-01 -6.6886e-01  3.5978e-01  4.4737e-01 -2.2255e-01\n",
      "  1.6679e-02 -2.4045e-01  5.5449e-01 -7.8809e-02  2.4600e-01  9.2955e-02\n",
      " -3.7373e-02  3.0215e-01  1.0050e-01  3.1506e-01  6.0226e-01  5.5959e-01\n",
      " -1.2215e-01  2.6837e-01 -8.2679e-01 -2.9379e-02  1.7350e-01 -6.5589e-01\n",
      " -2.7117e-01  2.2715e-01  3.8453e-01 -2.9517e-02 -3.0450e-01  4.3977e-01\n",
      " -4.8593e-01  4.2365e-01 -7.0111e-02 -4.6837e-01 -1.9011e-01 -2.3746e-02\n",
      " -4.7829e-02  5.4451e-01  4.6597e-01 -5.8662e-02  3.8888e-01  2.9006e-01\n",
      "  3.0576e-02  2.2720e-01 -5.7583e-01  1.2565e-01  1.9977e-01 -3.1947e-01\n",
      "  8.2808e-01 -3.0976e-02 -3.1661e-02 -4.8797e-01  4.6415e-01 -3.1599e-01\n",
      " -8.5216e-01 -7.0268e-01  8.3664e-02  5.6559e-01  4.5593e-01  9.8071e-03\n",
      "  4.1854e-01 -2.8402e-01  6.5484e-01  1.7777e-01  4.3339e-01 -5.4460e-01\n",
      "  1.1633e+00  2.9325e-01  7.4026e-01  1.9632e-01  2.4284e-01  1.6504e-01\n",
      "  6.4600e-01  4.1053e-01 -2.3752e-01 -3.1895e-01  7.4579e-01  6.3620e-01\n",
      " -6.1807e-01  5.5442e-02 -1.4914e-01 -6.4725e-01 -5.2697e-01 -6.4511e-01\n",
      " -1.9102e-01 -2.6380e-01 -1.6931e-01 -3.6162e-01  2.7033e-02 -2.0369e-01\n",
      "  1.3060e-01  3.2019e-01 -2.1124e+00  2.0008e-01  3.4881e-01 -1.4968e-01\n",
      "  3.3379e-01  6.9611e-01 -9.6421e-03 -5.0087e-01 -1.6512e-01 -5.6454e-01\n",
      " -4.2982e-01  1.1759e-01  4.7521e-01 -1.3207e-01 -2.0832e-02  7.6899e-02\n",
      " -7.4366e-02  4.5352e-01 -7.3842e-02  6.0398e-01  1.6719e-01  3.1527e-01\n",
      "  7.0987e-01  3.6808e-01  4.0145e-01 -1.0376e-01  1.9122e-03 -5.9801e-02\n",
      "  2.0957e-01  2.1146e-01  4.0668e-01  1.9950e-01  3.4589e-01  1.7253e-02\n",
      "  7.8303e-02  9.2941e-01 -7.2391e-01 -1.7390e-01  2.1626e-01 -8.5271e-01\n",
      "  6.7153e-01 -2.8578e-01  3.2857e-01  7.7583e-02 -2.4164e-01 -1.0281e-01\n",
      " -5.4860e-01 -3.1119e-01 -6.9961e-02 -1.9288e-01 -1.3204e-01 -3.1581e-01\n",
      " -1.5457e-01 -6.6062e-01  1.2630e-01  4.1621e-01  1.0281e+00  6.1761e-01\n",
      "  3.4091e-02  1.5702e-01 -3.6367e-01  3.3401e-02  5.1211e-01  1.2778e-01\n",
      "  4.0091e-01  3.8202e-01  1.8970e-01  5.8029e-01 -8.0392e-02  2.1924e-01\n",
      "  2.2515e-01 -1.2915e-01 -8.5990e-01 -2.4083e-01 -2.0393e-01 -5.7631e-01]\n"
     ]
    }
   ],
   "source": [
    "example_text = 'fridge' # even though out of index - can still get this\n",
    "\n",
    "print(embeddings_dictionary[example_text])\n",
    "\n",
    "embedding_layer = Embedding(num_words, emb_size , weights=[embedding_matrix], input_length=max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== develop model - additional structure featurea ====\n",
    "\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "\n",
    "decoder_targets_one_hot = zeros((\n",
    "        len(inputs), # not max words\n",
    "        max_output_len,\n",
    "        num_words_output\n",
    "    ),\n",
    "    dtype='float32'\n",
    ")\n",
    "# to fill with training output\n",
    "\n",
    "for i, d in enumerate(decoder_input_seq): # this section is where kernel dies - \n",
    "    for t, word in enumerate(d):\n",
    "        decoder_targets_one_hot[i, t, word] = 1\n",
    "        \n",
    "decoder_targets_one_hot[ex_val]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === encoder input \n",
    "\n",
    "nodes = 256 # unsure of impact to change this\n",
    "\n",
    "encoder_inputs_placeholder = Input(shape=(max_input_len,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = LSTM(nodes, return_state=True)\n",
    "\n",
    "encoder_outputs, h, c = encoder(x)\n",
    "encoder_states = [h, c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== define decoder\n",
    "\n",
    "decoder_inputs_placeholder = Input(shape=(max_output_len,))\n",
    "\n",
    "decoder_embedding = Embedding(num_words_output, nodes)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "decoder_lstm = LSTM(nodes, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
    "\n",
    "# model keeps removing all variables - so killing console\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Combine for Prediction and Error \n",
    "\n",
    "decoder_dense = Dense(num_words_output, activation = 'softmax')\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs_placeholder, \n",
    "  decoder_inputs_placeholder], decoder_outputs)\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy', # change loss value?\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model_plot_quenya.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = Fit Model\n",
    "\n",
    "# try to include tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 1\n",
    "\n",
    "r = model.fit(\n",
    "    [encoder_input_seq, decoder_input_seq],\n",
    "    decoder_targets_one_hot,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
